# DEEPKSEEK , QWEN , LlAMA , qWEEN , gEMMA AND OTHER MODELS, LOCALLY.

# Hardware is more and data is safe on your side.

# Use Docker for run the machine in VMS

# pull the ollama container -

# Open WebUI - pull from Docker Image

# in the open webUI connect with ollama opensourced model

# Sumamry - use Ollama basscially a tool to run models open source one using docker and pull it and use the open webUI to download those model form the ollama or use fastapi to create a api end point for getting a response.

# Hugging Face - Git Hub for llm models.
# its is a bumbed up version of ollama basically a github for machine learning folks.
# They can download like github models and run on theire machine fine tuning and upload works on datasets and even do a demo in the pages.

# Agentic AI:
# What is AI Agents? When do we call a llm as a agent?
#  LLM MODEL ARE DUMP SITING ON A SERVER AND TAKE INPUT AND RETURN OUTPUT . MAKING AGENTS WE NEED TO MAKE THEM PERFORM CERTAIN ACTION LIKE TALKING TO USER AND GOING THORUGH THE DB AND REPLY TO HUMAN AND SOLVE THE PROBLEM.

#NLP :
# ATTACHING THE BRAIN TO THE APPLICATIONS.
# llm - with software.
# llm - with hardware.
